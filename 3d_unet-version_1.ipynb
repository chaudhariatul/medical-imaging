{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09087acd-b631-464f-a286-030c981f9a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install python packages\n",
    "!pip install -q pandas pyathena boto3 requests pydicom IPython jupyter notebook aioboto3 pylibjpeg pylibjpeg-openjpeg pillow synapseclient nibabel pydicom nifti2dicom matplotlib split-folders torchinfo segmentation-models-pytorch-3d livelossplot torchmetrics tensorboard nilearn\n",
    "\n",
    "# # Install playwright and dependencies to export to PDF\n",
    "# !pip install -q nbconvert[webpdf]\n",
    "# !playwright install-deps\n",
    "# !playwright install chromium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbffa21f-5ab5-4437-803f-4331442b8149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import\tdataclass\n",
    "from IPython.display import\tclear_output, display\n",
    "from PIL import ImageShow\n",
    "from scipy import stats\n",
    "from torch.optim import Adam\n",
    "# from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing\timport List, Union\n",
    "import glob\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn\tas nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from tqdm import TqdmExperimentalWarning\n",
    "from tqdm.autonotebook import tqdm\n",
    "warnings.filterwarnings(\"ignore\", category=TqdmExperimentalWarning)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  print(\"The GPU is connected! :)\")\n",
    "else:\n",
    "  print(\"The GPU is not connected :(\")\n",
    "\n",
    "class GlobalConfig:\n",
    "    root_dir = 'brats2023/Data/BraTS-GLI'\n",
    "    train_root_dir = f'{root_dir}/train'\n",
    "    test_root_dir = f'{root_dir}/validate'\n",
    "    model_path = f'{root_dir}/models'\n",
    "    seed = 55\n",
    "    modalities = ['t1c', 't1n', 't2f', 't2w']\n",
    "    train_data_csv = './train_data.csv'\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "\n",
    "config = GlobalConfig()\n",
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee9439e-2398-42b3-83d1-76085b7c39a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's view the nifti files and 50th slice of all modalities.\n",
    "def load_nifti_file(file_path):\n",
    "    \"\"\"Helper function that loads a NIfTI file and return the data array.\"\"\"\n",
    "    niidata = nib.load(file_path)\n",
    "    data = niidata.get_fdata()\n",
    "    # Flip the image vertically\n",
    "    flip_data = np.flip(data, axis=0).copy()\n",
    "\n",
    "    return flip_data, data, niidata\n",
    "\n",
    "def get_patient_sorted_files(folder_path, required_modalities):\n",
    "    patient_count = 0\n",
    "    patient_folder_path = []\n",
    "    for patient_id in sorted(os.listdir(folder_path)):\n",
    "        modalities = sorted([f.split(\"-\")[-1].split('.nii.gz')[0] for f in os.listdir(f\"{folder_path}/{patient_id}\")])\n",
    "        if modalities == required_modalities:\n",
    "            file_dict = {}\n",
    "            file_dict['patient_id'] = patient_id\n",
    "            for mod in modalities:\n",
    "                filename = f\"{patient_id}-{mod}.nii.gz\"\n",
    "                filepath = os.path.join(folder_path, patient_id, filename)\n",
    "                file_dict[mod] = filepath\n",
    "            patient_folder_path.append(file_dict)\n",
    "        else:\n",
    "            print(f\"5 files not found in {folder_path}{patient_id}\")\n",
    "        patient_count += 1\n",
    "    return patient_folder_path\n",
    "\n",
    "validate_data_df = pd.DataFrame.from_records(get_patient_sorted_files(config.test_root_dir, config.modalities))\n",
    "training_data_df = pd.DataFrame.from_records(get_patient_sorted_files(config.train_root_dir, ['seg']+config.modalities))\n",
    "\n",
    "patient_index = random.randint(0, len(training_data_df))\n",
    "print(f\"Patient : {patient_index}\")\n",
    "patient_id = training_data_df.iloc[patient_index]['patient_id']\n",
    "patient_folder = f\"{config.train_root_dir}/{patient_id}\"\n",
    "slice_number = 50\n",
    "training_modalities = config.modalities + ['seg']\n",
    "fig, axs = plt.subplots(1, len(training_modalities), figsize=(16, 8))\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    file_path = f\"{patient_folder}\"\n",
    "    flip_data, data, niidata = load_nifti_file(os.path.join(patient_folder, f\"{patient_id}-{training_modalities[i]}.nii.gz\"))\n",
    "    ax.imshow(flip_data[:, :, slice_number], cmap='gray')\n",
    "    ax.set_title(training_modalities[i])\n",
    "    ax.axis('off')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de22743-2ba3-456e-bd68-10c58fd47558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using training_data_df\n",
    "\n",
    "class BratsDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df\n",
    "        self.modalities = config.modalities\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_ = self.df.loc[idx, 'patient_id']\n",
    "        df_modalities = self.df.columns.to_list()[1:]\n",
    "        images = []\n",
    "        for modality in df_modalities:\n",
    "            if modality == 'seg':\n",
    "                mask_path = self.df.loc[idx, modality]\n",
    "                mask = self.load_img(mask_path)\n",
    "                mask = self.preprocess_mask_labels(mask)\n",
    "            else:\n",
    "                img_path = self.df.loc[idx, modality]\n",
    "                img = self.load_img(img_path)\n",
    "                img = self.normalize(img)\n",
    "                images.append(img)\n",
    "        img = np.stack(images)\n",
    "        img = np.moveaxis(img, (0, 1, 2, 3), (0, 3, 2, 1))\n",
    "\n",
    "        if 'seg' in df_modalities:\n",
    "            return { \"Id\": id_, \"image\": img, \"mask\": mask}\n",
    "        else:\n",
    "            return { \"Id\": id_, \"image\": img}\n",
    "\n",
    "    def load_img(self, file_path):\n",
    "        data = nib.load(file_path)\n",
    "        data = np.asarray(data.dataobj)\n",
    "        return data\n",
    "\n",
    "    def normalize(self, data: np.ndarray):\n",
    "        data_min = np.min(data)\n",
    "        return (data - data_min) / (np.max(data) - data_min)\n",
    "\n",
    "    def resize(self, data: np.ndarray):\n",
    "        data = resize(data, (78, 120, 120), preserve_range=True)\n",
    "        return data\n",
    "\n",
    "    def preprocess_mask_labels(self, mask: np.ndarray):\n",
    "\n",
    "        mask_WT = mask.copy()\n",
    "        mask_WT[mask_WT == 1] = 1\n",
    "        mask_WT[mask_WT == 2] = 1\n",
    "        mask_WT[mask_WT == 4] = 1\n",
    "\n",
    "        mask_TC = mask.copy()\n",
    "        mask_TC[mask_TC == 1] = 1\n",
    "        mask_TC[mask_TC == 2] = 0\n",
    "        mask_TC[mask_TC == 4] = 1\n",
    "\n",
    "        mask_ET = mask.copy()\n",
    "        mask_ET[mask_ET == 1] = 0\n",
    "        mask_ET[mask_ET == 2] = 0\n",
    "        mask_ET[mask_ET == 4] = 1\n",
    "\n",
    "        mask = np.stack([mask_WT, mask_TC, mask_ET])\n",
    "        mask = np.moveaxis(mask, (0, 1, 2, 3), (0, 3, 2, 1))\n",
    "\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65204727-e193-42b8-9508-f5b4da879bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_loader(batch_size, num_workers):\n",
    "    dataset = BratsDataset(training_data_df)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    \n",
    "    data = next(iter(dataloader))\n",
    "    print(data['Id'], data['image'].shape, data['mask'].shape)\n",
    "    \n",
    "    img_tensor = data['image'][0].squeeze()[0].cpu().detach().numpy() \n",
    "    mask_tensor = data['mask'][0].squeeze()[0].squeeze().cpu().detach().numpy()\n",
    "    print(\"Num uniq Image values :\", len(np.unique(img_tensor, return_counts=True)[0]))\n",
    "    print(\"Min/Max Image values:\", img_tensor.min(), img_tensor.max())\n",
    "    print(\"Num uniq Mask values:\", np.unique(mask_tensor, return_counts=True))\n",
    "    \n",
    "    image = np.rot90(montage(img_tensor))\n",
    "    mask = np.rot90(montage(mask_tensor))\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize = (20, 20))\n",
    "    ax.imshow(image, cmap ='bone')\n",
    "    ax.imshow(np.ma.masked_where(mask == False, mask), cmap='cool', alpha=0.6)\n",
    "\n",
    "test_data_loader(batch_size=4, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf9a3be-4371-49b1-a178-f8df6183f817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "\n",
    "def dice_coef_metric(probabilities: torch.Tensor,\n",
    "                     truth: torch.Tensor,\n",
    "                     treshold: float = 0.5,\n",
    "                     eps: float = 1e-9) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate Dice score for data batch.\n",
    "    Params:\n",
    "        probobilities: model outputs after activation function.\n",
    "        truth: truth values.\n",
    "        threshold: threshold for probabilities.\n",
    "        eps: additive to refine the estimate.\n",
    "        Returns: dice score aka f1.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    num = probabilities.shape[0]\n",
    "    predictions = (probabilities >= treshold).float()\n",
    "    assert(predictions.shape == truth.shape)\n",
    "    for i in range(num):\n",
    "        prediction = predictions[i]\n",
    "        truth_ = truth[i]\n",
    "        intersection = 2.0 * (truth_ * prediction).sum()\n",
    "        union = truth_.sum() + prediction.sum()\n",
    "        if truth_.sum() == 0 and prediction.sum() == 0:\n",
    "            scores.append(1.0)\n",
    "        else:\n",
    "            score = (intersection + eps) / (union + eps)  # Added eps to denominator\n",
    "            scores.append(min(max(score.item(), 0.0), 1.0))  # Clamp between 0 and 1\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "def jaccard_coef_metric(probabilities: torch.Tensor,\n",
    "               truth: torch.Tensor,\n",
    "               treshold: float = 0.5,\n",
    "               eps: float = 1e-9) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate Jaccard index for data batch.\n",
    "    Params:\n",
    "        probobilities: model outputs after activation function.\n",
    "        truth: truth values.\n",
    "        threshold: threshold for probabilities.\n",
    "        eps: additive to refine the estimate.\n",
    "        Returns: jaccard score aka iou.\"\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    num = probabilities.shape[0]\n",
    "    predictions = (probabilities >= treshold).float()\n",
    "    assert(predictions.shape == truth.shape)\n",
    "    for i in range(num):\n",
    "        prediction = predictions[i]\n",
    "        truth_ = truth[i]\n",
    "        intersection = (prediction * truth_).sum()\n",
    "        union = (prediction.sum() + truth_.sum()) - intersection\n",
    "        if truth_.sum() == 0 and prediction.sum() == 0:\n",
    "            scores.append(1.0)\n",
    "        else:\n",
    "            score = (intersection + eps) / (union + eps)  # Added eps to denominator\n",
    "            scores.append(min(max(score.item(), 0.0), 1.0))  # Clamp between 0 and 1\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"Calculate dice loss.\"\"\"\n",
    "    def __init__(self, eps: float = 1e-9):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self,\n",
    "                logits: torch.Tensor,\n",
    "                targets: torch.Tensor) -> torch.Tensor:\n",
    "        num = targets.size(0)\n",
    "        probability = torch.sigmoid(logits)\n",
    "        probability = probability.view(num, -1)\n",
    "        targets = targets.view(num, -1)\n",
    "        assert(probability.shape == targets.shape)\n",
    "        intersection = 2.0 * (probability * targets).sum()\n",
    "        union = probability.sum() + targets.sum()\n",
    "        dice_score = (intersection + self.eps) / (union + self.eps)  # Added eps to denominator\n",
    "        dice_score = torch.clamp(dice_score, 0.0, 1.0)  # Clamp between 0 and 1\n",
    "        return 1.0 - dice_score\n",
    "\n",
    "\n",
    "class BCEDiceLoss(nn.Module):\n",
    "    \"\"\"Compute objective loss: BCE loss + DICE loss.\"\"\"\n",
    "    def __init__(self):\n",
    "        super(BCEDiceLoss, self).__init__()\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "        self.dice = DiceLoss()\n",
    "\n",
    "    def forward(self, \n",
    "                logits: torch.Tensor,\n",
    "                targets: torch.Tensor) -> torch.Tensor:\n",
    "        assert(logits.shape == targets.shape)\n",
    "        dice_loss = self.dice(logits, targets)\n",
    "        bce_loss = self.bce(logits, targets)\n",
    "\n",
    "        return bce_loss + dice_loss\n",
    "\n",
    "\n",
    "class Meter:\n",
    "    '''factory for storing and updating iou and dice scores.'''\n",
    "    def __init__(self, treshold: float = 0.5):\n",
    "        self.threshold: float = treshold\n",
    "        self.dice_scores: list = []\n",
    "        self.iou_scores: list = []\n",
    "    \n",
    "    def update(self, logits: torch.Tensor, targets: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Takes: logits from output model and targets,\n",
    "        calculates dice and iou scores, and stores them in lists.\n",
    "        \"\"\"\n",
    "        probs = torch.sigmoid(logits)\n",
    "        dice = dice_coef_metric(probs, targets, self.threshold)\n",
    "        iou = jaccard_coef_metric(probs, targets, self.threshold)\n",
    "        \n",
    "        self.dice_scores.append(dice)\n",
    "        self.iou_scores.append(iou)\n",
    "    \n",
    "    def get_metrics(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Returns: the average of the accumulated dice and iou scores.\n",
    "        \"\"\"\n",
    "        dice = np.mean(self.dice_scores)\n",
    "        iou = np.mean(self.iou_scores)\n",
    "        return dice, iou\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f4e3af-071d-4aaf-aecb-cd9182d30ee6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(Conv3D -> BN -> ReLU) * 2\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, num_groups=8):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.BatchNorm3d(out_channels),\n",
    "            nn.GroupNorm(num_groups=num_groups, num_channels=out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv3d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.BatchNorm3d(out_channels),\n",
    "            nn.GroupNorm(num_groups=num_groups, num_channels=out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "          )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.MaxPool3d(2, 2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, trilinear=True):\n",
    "        super().__init__()\n",
    "        if trilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose3d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "\n",
    "        diffZ = x2.size()[2] - x1.size()[2]\n",
    "        diffY = x2.size()[3] - x1.size()[3]\n",
    "        diffX = x2.size()[4] - x1.size()[4]\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2, diffZ // 2, diffZ - diffZ // 2])\n",
    "\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Out(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class UNet3d(nn.Module):\n",
    "    def __init__(self, in_channels, n_classes, n_channels):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.n_channels = n_channels\n",
    "\n",
    "        self.conv = DoubleConv(in_channels, n_channels)\n",
    "        self.enc1 = Down(n_channels, 2 * n_channels)\n",
    "        self.enc2 = Down(2 * n_channels, 4 * n_channels)\n",
    "        self.enc3 = Down(4 * n_channels, 8 * n_channels)\n",
    "        self.enc4 = Down(8 * n_channels, 8 * n_channels)\n",
    "\n",
    "        self.dec1 = Up(16 * n_channels, 4 * n_channels)\n",
    "        self.dec2 = Up(8 * n_channels, 2 * n_channels)\n",
    "        self.dec3 = Up(4 * n_channels, n_channels)\n",
    "        self.dec4 = Up(2 * n_channels, n_channels)\n",
    "        self.out = Out(n_channels, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv(x)\n",
    "        x2 = self.enc1(x1)\n",
    "        x3 = self.enc2(x2)\n",
    "        x4 = self.enc3(x3)\n",
    "        x5 = self.enc4(x4)\n",
    "\n",
    "        mask = self.dec1(x5, x4)\n",
    "        mask = self.dec2(mask, x3)\n",
    "        mask = self.dec3(mask, x2)\n",
    "        mask = self.dec4(mask, x1)\n",
    "        mask = self.out(mask)\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee616b61-9e67-4ddc-b36a-93235bc09d5d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self,\n",
    "                 net: nn.Module,\n",
    "                 dataset: torch.utils.data.Dataset,\n",
    "                 criterion: nn.Module,\n",
    "                 lr: float,\n",
    "                 accumulation_steps: int,\n",
    "                 batch_size: int,\n",
    "                 num_workers: int,\n",
    "                 fold: int,\n",
    "                 num_epochs: int,\n",
    "                 # train_data_csv: config.train_data_csv,\n",
    "                 display_plot: bool = True,\n",
    "                ):\n",
    "\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(\"device:\", self.device)\n",
    "        self.display_plot = display_plot\n",
    "        self.net = net\n",
    "        self.net = self.net.to(self.device)\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = Adam(self.net.parameters(), lr=lr)\n",
    "        self.scheduler = ReduceLROnPlateau(self.optimizer, mode=\"min\",\n",
    "                                           patience=2, verbose=True)\n",
    "        self.accumulation_steps = accumulation_steps // batch_size\n",
    "        self.phases = [\"train\", \"val\"]\n",
    "        self.num_epochs = num_epochs\n",
    "\n",
    "        self.dataloaders = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True,\n",
    "            shuffle=True,\n",
    "        )\n",
    "        self.best_loss = float(\"inf\")\n",
    "        self.losses = {phase: [] for phase in self.phases}\n",
    "        self.dice_scores = {phase: [] for phase in self.phases}\n",
    "        self.jaccard_scores = {phase: [] for phase in self.phases}\n",
    "\n",
    "    def _compute_loss_and_outputs(self,\n",
    "                                  images: torch.Tensor,\n",
    "                                  targets: torch.Tensor):\n",
    "        images = images.to(self.device).float()\n",
    "        targets = targets.to(self.device).float()\n",
    "        logits = self.net(images)\n",
    "        loss = self.criterion(logits, targets)\n",
    "        return loss, logits\n",
    "\n",
    "    def _do_epoch(self, epoch: int, phase: str):\n",
    "        print(f\"{phase} epoch: {epoch} | time: {time.strftime('%H:%M:%S')}\")\n",
    "\n",
    "        self.net.train() if phase == \"train\" else self.net.eval()\n",
    "        meter = Meter()\n",
    "        dataloader = self.dataloaders\n",
    "        total_batches = len(dataloader)\n",
    "        running_loss = 0.0\n",
    "        self.optimizer.zero_grad()\n",
    "        pbar = tqdm(enumerate(dataloader), total=total_batches, desc=f\"{phase} {epoch}\", leave=False)\n",
    "        for itr, data_batch in pbar:\n",
    "            images, targets = data_batch['image'], data_batch['mask']\n",
    "            loss, logits = self._compute_loss_and_outputs(images, targets)\n",
    "            loss = loss / self.accumulation_steps\n",
    "            if phase == \"train\":\n",
    "                loss.backward()\n",
    "                if (itr + 1) % self.accumulation_steps == 0:\n",
    "                    self.optimizer.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "            running_loss += loss.item()\n",
    "            meter.update(logits.detach().cpu(), targets.detach().cpu())\n",
    "\n",
    "        epoch_loss = (running_loss * self.accumulation_steps) / total_batches\n",
    "        epoch_dice, epoch_iou = meter.get_metrics()\n",
    "\n",
    "        self.losses[phase].append(epoch_loss)\n",
    "        self.dice_scores[phase].append(epoch_dice)\n",
    "        self.jaccard_scores[phase].append(epoch_iou)\n",
    "\n",
    "        return epoch_loss\n",
    "\n",
    "    def run(self):\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self._do_epoch(epoch, \"train\")\n",
    "            with torch.no_grad():\n",
    "                val_loss = self._do_epoch(epoch, \"val\")\n",
    "                self.scheduler.step(val_loss)\n",
    "            if self.display_plot:\n",
    "                self._plot_train_history()\n",
    "\n",
    "            if val_loss < self.best_loss:\n",
    "                print(f\"\\n{'#'*20}\\nSaved new checkpoint\\n{'#'*20}\\n\")\n",
    "                self.best_loss = val_loss\n",
    "                torch.save(self.net.state_dict(), \"best_model.pth\")\n",
    "            print()\n",
    "        self._save_train_history()\n",
    "\n",
    "    def _plot_train_history(self):\n",
    "        data = [self.losses, self.dice_scores, self.jaccard_scores]\n",
    "        colors = ['deepskyblue', \"crimson\"]\n",
    "        labels = [\n",
    "            f\"\"\"\n",
    "            train loss {self.losses['train'][-1]}\n",
    "            val loss {self.losses['val'][-1]}\n",
    "            \"\"\",\n",
    "\n",
    "            f\"\"\"\n",
    "            train dice score {self.dice_scores['train'][-1]}\n",
    "            val dice score {self.dice_scores['val'][-1]}\n",
    "            \"\"\",\n",
    "\n",
    "            f\"\"\"\n",
    "            train jaccard score {self.jaccard_scores['train'][-1]}\n",
    "            val jaccard score {self.jaccard_scores['val'][-1]}\n",
    "            \"\"\",\n",
    "        ]\n",
    "\n",
    "        clear_output(True)\n",
    "        with plt.style.context(\"seaborn-v0_8-notebook\"):\n",
    "            fig, axes = plt.subplots(3, 1, figsize=(8, 10))\n",
    "            for i, ax in enumerate(axes):\n",
    "                ax.plot(data[i]['val'], c=colors[0], label=\"val\")\n",
    "                ax.plot(data[i]['train'], c=colors[-1], label=\"train\")\n",
    "                ax.set_title(labels[i])\n",
    "                ax.legend(loc=\"upper right\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    def load_predtrain_model(self,\n",
    "                             state_path: str):\n",
    "        self.net.load_state_dict(torch.load(state_path))\n",
    "        print(\"Predtrain model loaded\")\n",
    "\n",
    "    def _save_train_history(self):\n",
    "        \"\"\"writing model weights and training logs to files.\"\"\"\n",
    "        torch.save(self.net.state_dict(),\n",
    "                   f\"last_epoch_model.pth\")\n",
    "\n",
    "        logs_ = [self.losses, self.dice_scores, self.jaccard_scores]\n",
    "        log_names_ = [\"_loss\", \"_dice\", \"_jaccard\"]\n",
    "        logs = [logs_[i][key] for i in list(range(len(logs_)))\n",
    "                         for key in logs_[i]]\n",
    "        log_names = [key+log_names_[i]\n",
    "                     for i in list(range(len(logs_)))\n",
    "                     for key in logs_[i]\n",
    "                    ]\n",
    "        pd.DataFrame(\n",
    "            dict(zip(log_names, logs))\n",
    "        ).to_csv(\"train_log.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3872f8b8-9079-46cf-abf2-93c203ce0890",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nodel = UNet3d(in_channels=4, n_classes=3, n_channels=24).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede0c1c8-9240-4be9-89c8-aa8e79dfb203",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "trainer = Trainer(\n",
    "            net=nodel,\n",
    "            dataset=BratsDataset(training_data_df),\n",
    "            criterion=BCEDiceLoss(),\n",
    "            lr=5e-4,\n",
    "            accumulation_steps=4,\n",
    "            batch_size=1,\n",
    "            num_workers=8,\n",
    "            fold=0,\n",
    "            num_epochs=50,)\n",
    "\n",
    "trainer.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
